{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PythonProject (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical, plot_model\n",
        "import cv2\n",
        "import os"
      ],
      "metadata": {
        "id": "vO4z8QrAR7Bp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaWCN4kAUx6N",
        "outputId": "89f1cccb-f71b-4aef-c9c2-c0335a34894e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#read the image\n",
        "# function to load the dataset and return the dataset list\n",
        "# containing elements of format [scans, target]\n",
        "targets = ['PNEUMONIA', 'NORMAL']\n",
        "img_size = 150\n",
        "def get_training_data(scans):\n",
        "    data = list()\n",
        "    for target in targets: \n",
        "        path = os.path.join(scans, target)\n",
        "        class_label = targets.index(target)\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
        "                resized_arr = cv2.resize(arr, (img_size, img_size))\n",
        "                data.append([resized_arr, class_label])\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "    return np.array(data)"
      ],
      "metadata": {
        "id": "byCDbapvR9a5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#extracting the dataset\n",
        "train = get_training_data('/content/gdrive/MyDrive/PythonProjectWebApp/chest_xray/train')\n",
        "test = get_training_data('/content/gdrive/MyDrive/PythonProjectWebApp/chest_xray/test')\n",
        "val = get_training_data('/content/gdrive/MyDrive/PythonProjectWebApp/chest_xray/val')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3r_2GF16SCER",
        "outputId": "19d383be-a9ff-4454-caf2-7277a797f042"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#split the data into training, testing and validation groups with variables to hold the target names.\n",
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "X_val = []\n",
        "y_val = []\n",
        "\n",
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "for image_scan, target in train:\n",
        "    X_train.append(image_scan)\n",
        "    y_train.append(target)\n",
        "\n",
        "for image_scan, target in test:\n",
        "    X_test.append(image_scan)\n",
        "    y_test.append(target)\n",
        "    \n",
        "for image_scan, target in val:\n",
        "    X_val.append(image_scan)\n",
        "    y_val.append(target)"
      ],
      "metadata": {
        "id": "0KGt9sgiVT3r"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize data\n",
        "X_train = np.array(X_train) / 255\n",
        "X_val = np.array(X_val) / 255\n",
        "X_test = np.array(X_test) / 255"
      ],
      "metadata": {
        "id": "h8HJLgHSXRo6"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# resize data\n",
        "X_train = X_train.reshape(-1, img_size, img_size, 1)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "X_val = X_val.reshape(-1, img_size, img_size, 1)\n",
        "y_val = np.array(y_val)\n",
        "\n",
        "X_test = X_test.reshape(-1, img_size, img_size, 1)\n",
        "y_test = np.array(y_test)"
      ],
      "metadata": {
        "id": "AiJ-prNWVbjz"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prevents overfitting and handles the imbalance in dataset\n",
        "\n",
        "data_aug = ImageDataGenerator(\n",
        "        rotation_range = 30,  #rotate \n",
        "        zoom_range = 0.2, #  zoom  \n",
        "        width_shift_range=0.1,  #  shift images horizontally \n",
        "        height_shift_range=0.1,  #  shift images vertically\n",
        "        horizontal_flip = True,  # flip images\n",
        "        vertical_flip=False)  # no vertical flip\n",
        "\n",
        "data_aug.fit(X_train)"
      ],
      "metadata": {
        "id": "76nsGFBAVgcb"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#building the model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32 , (3,3) , padding = 'same' , activation = 'relu' , input_shape = (150,150,1)))\n",
        "model.add(MaxPool2D((2,2) , strides = 2))\n",
        "\n",
        "model.add(Conv2D(64 , (3,3) , padding = 'same' , activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(MaxPool2D((2,2) , strides = 2))\n",
        "\n",
        "model.add(Conv2D(64 , (3,3) , padding = 'same' , activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(MaxPool2D((2,2) , strides = 2 ))\n",
        "\n",
        "model.add(Conv2D(128 , (3,3) , padding = 'same' , activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(MaxPool2D((2,2) , strides = 2))\n",
        "\n",
        "model.add(Conv2D(256 , (3,3)  , padding = 'same' , activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D((2,2) , strides = 2))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units = 1 , activation = 'sigmoid'))\n",
        "\n",
        "model.compile(optimizer = \"rmsprop\" , loss = 'binary_crossentropy' , metrics = ['acc'])\n",
        "model.summary()\n",
        "plot_model(model, to_file = 'model_plot.png', show_shapes = True, show_layer_names = True)"
      ],
      "metadata": {
        "id": "R8AQPHe7VjBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#learning rate reduction\n",
        "LRR = ReduceLROnPlateau(monitor='val_acc', patience = 2, verbose=1,factor=0.3, min_lr=0.000001)"
      ],
      "metadata": {
        "id": "xrHIuCnyVjcs"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(data_aug.flow(X_train, y_train, batch_size = 44) , epochs = 16 , validation_data = data_aug.flow(X_val, y_val) , callbacks = [LRR])"
      ],
      "metadata": {
        "id": "cXnRCWP3VltT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "414b62a0-864f-499b-d61e-d885432f3e56"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/16\n",
            "119/119 [==============================] - 12s 94ms/step - loss: 0.5156 - acc: 0.7855 - val_loss: 1.0312 - val_acc: 0.5000 - lr: 0.0010\n",
            "Epoch 2/16\n",
            "119/119 [==============================] - 10s 82ms/step - loss: 0.3108 - acc: 0.8763 - val_loss: 0.8178 - val_acc: 0.5625 - lr: 0.0010\n",
            "Epoch 3/16\n",
            "119/119 [==============================] - 10s 83ms/step - loss: 0.2817 - acc: 0.8892 - val_loss: 1.0245 - val_acc: 0.5000 - lr: 0.0010\n",
            "Epoch 4/16\n",
            "119/119 [==============================] - ETA: 0s - loss: 0.2407 - acc: 0.9055\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "119/119 [==============================] - 10s 83ms/step - loss: 0.2407 - acc: 0.9055 - val_loss: 1.2569 - val_acc: 0.5000 - lr: 0.0010\n",
            "Epoch 5/16\n",
            "119/119 [==============================] - 10s 82ms/step - loss: 0.1733 - acc: 0.9333 - val_loss: 0.6216 - val_acc: 0.7500 - lr: 3.0000e-04\n",
            "Epoch 6/16\n",
            "119/119 [==============================] - 10s 83ms/step - loss: 0.1545 - acc: 0.9404 - val_loss: 0.9365 - val_acc: 0.5000 - lr: 3.0000e-04\n",
            "Epoch 7/16\n",
            "119/119 [==============================] - ETA: 0s - loss: 0.1428 - acc: 0.9459\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "119/119 [==============================] - 10s 83ms/step - loss: 0.1428 - acc: 0.9459 - val_loss: 0.6408 - val_acc: 0.5625 - lr: 3.0000e-04\n",
            "Epoch 8/16\n",
            "119/119 [==============================] - 10s 82ms/step - loss: 0.1219 - acc: 0.9549 - val_loss: 0.9477 - val_acc: 0.5000 - lr: 9.0000e-05\n",
            "Epoch 9/16\n",
            "119/119 [==============================] - ETA: 0s - loss: 0.1287 - acc: 0.9526\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "119/119 [==============================] - 10s 83ms/step - loss: 0.1287 - acc: 0.9526 - val_loss: 0.8939 - val_acc: 0.6250 - lr: 9.0000e-05\n",
            "Epoch 10/16\n",
            "119/119 [==============================] - 10s 83ms/step - loss: 0.1188 - acc: 0.9578 - val_loss: 0.6671 - val_acc: 0.6250 - lr: 2.7000e-05\n",
            "Epoch 11/16\n",
            "119/119 [==============================] - ETA: 0s - loss: 0.1126 - acc: 0.9553\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "119/119 [==============================] - 10s 84ms/step - loss: 0.1126 - acc: 0.9553 - val_loss: 0.8221 - val_acc: 0.5625 - lr: 2.7000e-05\n",
            "Epoch 12/16\n",
            "119/119 [==============================] - 10s 82ms/step - loss: 0.1188 - acc: 0.9574 - val_loss: 0.7332 - val_acc: 0.5625 - lr: 8.1000e-06\n",
            "Epoch 13/16\n",
            "119/119 [==============================] - ETA: 0s - loss: 0.1189 - acc: 0.9584\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
            "119/119 [==============================] - 10s 83ms/step - loss: 0.1189 - acc: 0.9584 - val_loss: 0.6923 - val_acc: 0.5625 - lr: 8.1000e-06\n",
            "Epoch 14/16\n",
            "119/119 [==============================] - 10s 82ms/step - loss: 0.1151 - acc: 0.9590 - val_loss: 0.8010 - val_acc: 0.5000 - lr: 2.4300e-06\n",
            "Epoch 15/16\n",
            "119/119 [==============================] - ETA: 0s - loss: 0.1156 - acc: 0.9530\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "119/119 [==============================] - 10s 83ms/step - loss: 0.1156 - acc: 0.9530 - val_loss: 0.7550 - val_acc: 0.6875 - lr: 2.4300e-06\n",
            "Epoch 16/16\n",
            "119/119 [==============================] - 10s 83ms/step - loss: 0.1114 - acc: 0.9597 - val_loss: 0.7374 - val_acc: 0.6250 - lr: 1.0000e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('PNmodel.h5')"
      ],
      "metadata": {
        "id": "xjeL48eiKrkT"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loss:\" , model.evaluate(X_test,y_test)[0])\n",
        "print(\"Accuracy:\" , model.evaluate(X_test,y_test)[1])"
      ],
      "metadata": {
        "id": "ZCxS2UGhVoJT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3834788c-e2fd-48a3-abff-ac8428b4e3eb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 10ms/step - loss: 0.2633 - acc: 0.9167\n",
            "Loss: 0.2633186876773834\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.2633 - acc: 0.9167\n",
            "Accuracy: 0.9166666865348816\n"
          ]
        }
      ]
    }
  ]
}